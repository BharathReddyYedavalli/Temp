{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d55fa88",
   "metadata": {},
   "source": [
    "# Model Label Investigation\n",
    "\n",
    "This notebook investigates the label mapping used during training to understand why predictions might be incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a8cfc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EfficientNet Directory ===\n",
      "  - best_glaucoma_model.pth\n",
      "  - glaucoma_results.png\n",
      "  - Labels.csv\n",
      "  - model.ipynb\n",
      "\n",
      "=== MobileNetV3-Large Directory ===\n",
      "  - best_glaucoma_model.pth\n",
      "  - model.ipynb\n",
      "\n",
      "=== ResNet50 Directory ===\n",
      "  - best_glaucoma_model.pth\n",
      "  - glaucoma_training_results.png\n",
      "  - model.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Check what's in each model directory\n",
    "model_dirs = ['EfficientNet', 'MobileNetV3-Large', 'ResNet50']\n",
    "\n",
    "for model_dir in model_dirs:\n",
    "    print(f\"\\n=== {model_dir} Directory ===\")\n",
    "    path = Path(model_dir)\n",
    "    if path.exists():\n",
    "        files = list(path.glob('*'))\n",
    "        for file in files:\n",
    "            print(f\"  - {file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ccf89e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model: EfficientNet\\best_glaucoma_model.pth ===\n",
      "Checkpoint keys: ['features.0.0.weight', 'features.0.1.weight', 'features.0.1.bias', 'features.0.1.running_mean', 'features.0.1.running_var', 'features.0.1.num_batches_tracked', 'features.1.0.block.0.0.weight', 'features.1.0.block.0.1.weight', 'features.1.0.block.0.1.bias', 'features.1.0.block.0.1.running_mean', 'features.1.0.block.0.1.running_var', 'features.1.0.block.0.1.num_batches_tracked', 'features.1.0.block.1.fc1.weight', 'features.1.0.block.1.fc1.bias', 'features.1.0.block.1.fc2.weight', 'features.1.0.block.1.fc2.bias', 'features.1.0.block.2.0.weight', 'features.1.0.block.2.1.weight', 'features.1.0.block.2.1.bias', 'features.1.0.block.2.1.running_mean', 'features.1.0.block.2.1.running_var', 'features.1.0.block.2.1.num_batches_tracked', 'features.2.0.block.0.0.weight', 'features.2.0.block.0.1.weight', 'features.2.0.block.0.1.bias', 'features.2.0.block.0.1.running_mean', 'features.2.0.block.0.1.running_var', 'features.2.0.block.0.1.num_batches_tracked', 'features.2.0.block.1.0.weight', 'features.2.0.block.1.1.weight', 'features.2.0.block.1.1.bias', 'features.2.0.block.1.1.running_mean', 'features.2.0.block.1.1.running_var', 'features.2.0.block.1.1.num_batches_tracked', 'features.2.0.block.2.fc1.weight', 'features.2.0.block.2.fc1.bias', 'features.2.0.block.2.fc2.weight', 'features.2.0.block.2.fc2.bias', 'features.2.0.block.3.0.weight', 'features.2.0.block.3.1.weight', 'features.2.0.block.3.1.bias', 'features.2.0.block.3.1.running_mean', 'features.2.0.block.3.1.running_var', 'features.2.0.block.3.1.num_batches_tracked', 'features.2.1.block.0.0.weight', 'features.2.1.block.0.1.weight', 'features.2.1.block.0.1.bias', 'features.2.1.block.0.1.running_mean', 'features.2.1.block.0.1.running_var', 'features.2.1.block.0.1.num_batches_tracked', 'features.2.1.block.1.0.weight', 'features.2.1.block.1.1.weight', 'features.2.1.block.1.1.bias', 'features.2.1.block.1.1.running_mean', 'features.2.1.block.1.1.running_var', 'features.2.1.block.1.1.num_batches_tracked', 'features.2.1.block.2.fc1.weight', 'features.2.1.block.2.fc1.bias', 'features.2.1.block.2.fc2.weight', 'features.2.1.block.2.fc2.bias', 'features.2.1.block.3.0.weight', 'features.2.1.block.3.1.weight', 'features.2.1.block.3.1.bias', 'features.2.1.block.3.1.running_mean', 'features.2.1.block.3.1.running_var', 'features.2.1.block.3.1.num_batches_tracked', 'features.3.0.block.0.0.weight', 'features.3.0.block.0.1.weight', 'features.3.0.block.0.1.bias', 'features.3.0.block.0.1.running_mean', 'features.3.0.block.0.1.running_var', 'features.3.0.block.0.1.num_batches_tracked', 'features.3.0.block.1.0.weight', 'features.3.0.block.1.1.weight', 'features.3.0.block.1.1.bias', 'features.3.0.block.1.1.running_mean', 'features.3.0.block.1.1.running_var', 'features.3.0.block.1.1.num_batches_tracked', 'features.3.0.block.2.fc1.weight', 'features.3.0.block.2.fc1.bias', 'features.3.0.block.2.fc2.weight', 'features.3.0.block.2.fc2.bias', 'features.3.0.block.3.0.weight', 'features.3.0.block.3.1.weight', 'features.3.0.block.3.1.bias', 'features.3.0.block.3.1.running_mean', 'features.3.0.block.3.1.running_var', 'features.3.0.block.3.1.num_batches_tracked', 'features.3.1.block.0.0.weight', 'features.3.1.block.0.1.weight', 'features.3.1.block.0.1.bias', 'features.3.1.block.0.1.running_mean', 'features.3.1.block.0.1.running_var', 'features.3.1.block.0.1.num_batches_tracked', 'features.3.1.block.1.0.weight', 'features.3.1.block.1.1.weight', 'features.3.1.block.1.1.bias', 'features.3.1.block.1.1.running_mean', 'features.3.1.block.1.1.running_var', 'features.3.1.block.1.1.num_batches_tracked', 'features.3.1.block.2.fc1.weight', 'features.3.1.block.2.fc1.bias', 'features.3.1.block.2.fc2.weight', 'features.3.1.block.2.fc2.bias', 'features.3.1.block.3.0.weight', 'features.3.1.block.3.1.weight', 'features.3.1.block.3.1.bias', 'features.3.1.block.3.1.running_mean', 'features.3.1.block.3.1.running_var', 'features.3.1.block.3.1.num_batches_tracked', 'features.4.0.block.0.0.weight', 'features.4.0.block.0.1.weight', 'features.4.0.block.0.1.bias', 'features.4.0.block.0.1.running_mean', 'features.4.0.block.0.1.running_var', 'features.4.0.block.0.1.num_batches_tracked', 'features.4.0.block.1.0.weight', 'features.4.0.block.1.1.weight', 'features.4.0.block.1.1.bias', 'features.4.0.block.1.1.running_mean', 'features.4.0.block.1.1.running_var', 'features.4.0.block.1.1.num_batches_tracked', 'features.4.0.block.2.fc1.weight', 'features.4.0.block.2.fc1.bias', 'features.4.0.block.2.fc2.weight', 'features.4.0.block.2.fc2.bias', 'features.4.0.block.3.0.weight', 'features.4.0.block.3.1.weight', 'features.4.0.block.3.1.bias', 'features.4.0.block.3.1.running_mean', 'features.4.0.block.3.1.running_var', 'features.4.0.block.3.1.num_batches_tracked', 'features.4.1.block.0.0.weight', 'features.4.1.block.0.1.weight', 'features.4.1.block.0.1.bias', 'features.4.1.block.0.1.running_mean', 'features.4.1.block.0.1.running_var', 'features.4.1.block.0.1.num_batches_tracked', 'features.4.1.block.1.0.weight', 'features.4.1.block.1.1.weight', 'features.4.1.block.1.1.bias', 'features.4.1.block.1.1.running_mean', 'features.4.1.block.1.1.running_var', 'features.4.1.block.1.1.num_batches_tracked', 'features.4.1.block.2.fc1.weight', 'features.4.1.block.2.fc1.bias', 'features.4.1.block.2.fc2.weight', 'features.4.1.block.2.fc2.bias', 'features.4.1.block.3.0.weight', 'features.4.1.block.3.1.weight', 'features.4.1.block.3.1.bias', 'features.4.1.block.3.1.running_mean', 'features.4.1.block.3.1.running_var', 'features.4.1.block.3.1.num_batches_tracked', 'features.4.2.block.0.0.weight', 'features.4.2.block.0.1.weight', 'features.4.2.block.0.1.bias', 'features.4.2.block.0.1.running_mean', 'features.4.2.block.0.1.running_var', 'features.4.2.block.0.1.num_batches_tracked', 'features.4.2.block.1.0.weight', 'features.4.2.block.1.1.weight', 'features.4.2.block.1.1.bias', 'features.4.2.block.1.1.running_mean', 'features.4.2.block.1.1.running_var', 'features.4.2.block.1.1.num_batches_tracked', 'features.4.2.block.2.fc1.weight', 'features.4.2.block.2.fc1.bias', 'features.4.2.block.2.fc2.weight', 'features.4.2.block.2.fc2.bias', 'features.4.2.block.3.0.weight', 'features.4.2.block.3.1.weight', 'features.4.2.block.3.1.bias', 'features.4.2.block.3.1.running_mean', 'features.4.2.block.3.1.running_var', 'features.4.2.block.3.1.num_batches_tracked', 'features.5.0.block.0.0.weight', 'features.5.0.block.0.1.weight', 'features.5.0.block.0.1.bias', 'features.5.0.block.0.1.running_mean', 'features.5.0.block.0.1.running_var', 'features.5.0.block.0.1.num_batches_tracked', 'features.5.0.block.1.0.weight', 'features.5.0.block.1.1.weight', 'features.5.0.block.1.1.bias', 'features.5.0.block.1.1.running_mean', 'features.5.0.block.1.1.running_var', 'features.5.0.block.1.1.num_batches_tracked', 'features.5.0.block.2.fc1.weight', 'features.5.0.block.2.fc1.bias', 'features.5.0.block.2.fc2.weight', 'features.5.0.block.2.fc2.bias', 'features.5.0.block.3.0.weight', 'features.5.0.block.3.1.weight', 'features.5.0.block.3.1.bias', 'features.5.0.block.3.1.running_mean', 'features.5.0.block.3.1.running_var', 'features.5.0.block.3.1.num_batches_tracked', 'features.5.1.block.0.0.weight', 'features.5.1.block.0.1.weight', 'features.5.1.block.0.1.bias', 'features.5.1.block.0.1.running_mean', 'features.5.1.block.0.1.running_var', 'features.5.1.block.0.1.num_batches_tracked', 'features.5.1.block.1.0.weight', 'features.5.1.block.1.1.weight', 'features.5.1.block.1.1.bias', 'features.5.1.block.1.1.running_mean', 'features.5.1.block.1.1.running_var', 'features.5.1.block.1.1.num_batches_tracked', 'features.5.1.block.2.fc1.weight', 'features.5.1.block.2.fc1.bias', 'features.5.1.block.2.fc2.weight', 'features.5.1.block.2.fc2.bias', 'features.5.1.block.3.0.weight', 'features.5.1.block.3.1.weight', 'features.5.1.block.3.1.bias', 'features.5.1.block.3.1.running_mean', 'features.5.1.block.3.1.running_var', 'features.5.1.block.3.1.num_batches_tracked', 'features.5.2.block.0.0.weight', 'features.5.2.block.0.1.weight', 'features.5.2.block.0.1.bias', 'features.5.2.block.0.1.running_mean', 'features.5.2.block.0.1.running_var', 'features.5.2.block.0.1.num_batches_tracked', 'features.5.2.block.1.0.weight', 'features.5.2.block.1.1.weight', 'features.5.2.block.1.1.bias', 'features.5.2.block.1.1.running_mean', 'features.5.2.block.1.1.running_var', 'features.5.2.block.1.1.num_batches_tracked', 'features.5.2.block.2.fc1.weight', 'features.5.2.block.2.fc1.bias', 'features.5.2.block.2.fc2.weight', 'features.5.2.block.2.fc2.bias', 'features.5.2.block.3.0.weight', 'features.5.2.block.3.1.weight', 'features.5.2.block.3.1.bias', 'features.5.2.block.3.1.running_mean', 'features.5.2.block.3.1.running_var', 'features.5.2.block.3.1.num_batches_tracked', 'features.6.0.block.0.0.weight', 'features.6.0.block.0.1.weight', 'features.6.0.block.0.1.bias', 'features.6.0.block.0.1.running_mean', 'features.6.0.block.0.1.running_var', 'features.6.0.block.0.1.num_batches_tracked', 'features.6.0.block.1.0.weight', 'features.6.0.block.1.1.weight', 'features.6.0.block.1.1.bias', 'features.6.0.block.1.1.running_mean', 'features.6.0.block.1.1.running_var', 'features.6.0.block.1.1.num_batches_tracked', 'features.6.0.block.2.fc1.weight', 'features.6.0.block.2.fc1.bias', 'features.6.0.block.2.fc2.weight', 'features.6.0.block.2.fc2.bias', 'features.6.0.block.3.0.weight', 'features.6.0.block.3.1.weight', 'features.6.0.block.3.1.bias', 'features.6.0.block.3.1.running_mean', 'features.6.0.block.3.1.running_var', 'features.6.0.block.3.1.num_batches_tracked', 'features.6.1.block.0.0.weight', 'features.6.1.block.0.1.weight', 'features.6.1.block.0.1.bias', 'features.6.1.block.0.1.running_mean', 'features.6.1.block.0.1.running_var', 'features.6.1.block.0.1.num_batches_tracked', 'features.6.1.block.1.0.weight', 'features.6.1.block.1.1.weight', 'features.6.1.block.1.1.bias', 'features.6.1.block.1.1.running_mean', 'features.6.1.block.1.1.running_var', 'features.6.1.block.1.1.num_batches_tracked', 'features.6.1.block.2.fc1.weight', 'features.6.1.block.2.fc1.bias', 'features.6.1.block.2.fc2.weight', 'features.6.1.block.2.fc2.bias', 'features.6.1.block.3.0.weight', 'features.6.1.block.3.1.weight', 'features.6.1.block.3.1.bias', 'features.6.1.block.3.1.running_mean', 'features.6.1.block.3.1.running_var', 'features.6.1.block.3.1.num_batches_tracked', 'features.6.2.block.0.0.weight', 'features.6.2.block.0.1.weight', 'features.6.2.block.0.1.bias', 'features.6.2.block.0.1.running_mean', 'features.6.2.block.0.1.running_var', 'features.6.2.block.0.1.num_batches_tracked', 'features.6.2.block.1.0.weight', 'features.6.2.block.1.1.weight', 'features.6.2.block.1.1.bias', 'features.6.2.block.1.1.running_mean', 'features.6.2.block.1.1.running_var', 'features.6.2.block.1.1.num_batches_tracked', 'features.6.2.block.2.fc1.weight', 'features.6.2.block.2.fc1.bias', 'features.6.2.block.2.fc2.weight', 'features.6.2.block.2.fc2.bias', 'features.6.2.block.3.0.weight', 'features.6.2.block.3.1.weight', 'features.6.2.block.3.1.bias', 'features.6.2.block.3.1.running_mean', 'features.6.2.block.3.1.running_var', 'features.6.2.block.3.1.num_batches_tracked', 'features.6.3.block.0.0.weight', 'features.6.3.block.0.1.weight', 'features.6.3.block.0.1.bias', 'features.6.3.block.0.1.running_mean', 'features.6.3.block.0.1.running_var', 'features.6.3.block.0.1.num_batches_tracked', 'features.6.3.block.1.0.weight', 'features.6.3.block.1.1.weight', 'features.6.3.block.1.1.bias', 'features.6.3.block.1.1.running_mean', 'features.6.3.block.1.1.running_var', 'features.6.3.block.1.1.num_batches_tracked', 'features.6.3.block.2.fc1.weight', 'features.6.3.block.2.fc1.bias', 'features.6.3.block.2.fc2.weight', 'features.6.3.block.2.fc2.bias', 'features.6.3.block.3.0.weight', 'features.6.3.block.3.1.weight', 'features.6.3.block.3.1.bias', 'features.6.3.block.3.1.running_mean', 'features.6.3.block.3.1.running_var', 'features.6.3.block.3.1.num_batches_tracked', 'features.7.0.block.0.0.weight', 'features.7.0.block.0.1.weight', 'features.7.0.block.0.1.bias', 'features.7.0.block.0.1.running_mean', 'features.7.0.block.0.1.running_var', 'features.7.0.block.0.1.num_batches_tracked', 'features.7.0.block.1.0.weight', 'features.7.0.block.1.1.weight', 'features.7.0.block.1.1.bias', 'features.7.0.block.1.1.running_mean', 'features.7.0.block.1.1.running_var', 'features.7.0.block.1.1.num_batches_tracked', 'features.7.0.block.2.fc1.weight', 'features.7.0.block.2.fc1.bias', 'features.7.0.block.2.fc2.weight', 'features.7.0.block.2.fc2.bias', 'features.7.0.block.3.0.weight', 'features.7.0.block.3.1.weight', 'features.7.0.block.3.1.bias', 'features.7.0.block.3.1.running_mean', 'features.7.0.block.3.1.running_var', 'features.7.0.block.3.1.num_batches_tracked', 'features.8.0.weight', 'features.8.1.weight', 'features.8.1.bias', 'features.8.1.running_mean', 'features.8.1.running_var', 'features.8.1.num_batches_tracked', 'classifier.1.weight', 'classifier.1.bias']\n",
      "\n",
      "=== Model: MobileNetV3-Large\\best_glaucoma_model.pth ===\n",
      "Checkpoint keys: ['features.0.0.weight', 'features.0.1.weight', 'features.0.1.bias', 'features.0.1.running_mean', 'features.0.1.running_var', 'features.0.1.num_batches_tracked', 'features.1.block.0.0.weight', 'features.1.block.0.1.weight', 'features.1.block.0.1.bias', 'features.1.block.0.1.running_mean', 'features.1.block.0.1.running_var', 'features.1.block.0.1.num_batches_tracked', 'features.1.block.1.0.weight', 'features.1.block.1.1.weight', 'features.1.block.1.1.bias', 'features.1.block.1.1.running_mean', 'features.1.block.1.1.running_var', 'features.1.block.1.1.num_batches_tracked', 'features.2.block.0.0.weight', 'features.2.block.0.1.weight', 'features.2.block.0.1.bias', 'features.2.block.0.1.running_mean', 'features.2.block.0.1.running_var', 'features.2.block.0.1.num_batches_tracked', 'features.2.block.1.0.weight', 'features.2.block.1.1.weight', 'features.2.block.1.1.bias', 'features.2.block.1.1.running_mean', 'features.2.block.1.1.running_var', 'features.2.block.1.1.num_batches_tracked', 'features.2.block.2.0.weight', 'features.2.block.2.1.weight', 'features.2.block.2.1.bias', 'features.2.block.2.1.running_mean', 'features.2.block.2.1.running_var', 'features.2.block.2.1.num_batches_tracked', 'features.3.block.0.0.weight', 'features.3.block.0.1.weight', 'features.3.block.0.1.bias', 'features.3.block.0.1.running_mean', 'features.3.block.0.1.running_var', 'features.3.block.0.1.num_batches_tracked', 'features.3.block.1.0.weight', 'features.3.block.1.1.weight', 'features.3.block.1.1.bias', 'features.3.block.1.1.running_mean', 'features.3.block.1.1.running_var', 'features.3.block.1.1.num_batches_tracked', 'features.3.block.2.0.weight', 'features.3.block.2.1.weight', 'features.3.block.2.1.bias', 'features.3.block.2.1.running_mean', 'features.3.block.2.1.running_var', 'features.3.block.2.1.num_batches_tracked', 'features.4.block.0.0.weight', 'features.4.block.0.1.weight', 'features.4.block.0.1.bias', 'features.4.block.0.1.running_mean', 'features.4.block.0.1.running_var', 'features.4.block.0.1.num_batches_tracked', 'features.4.block.1.0.weight', 'features.4.block.1.1.weight', 'features.4.block.1.1.bias', 'features.4.block.1.1.running_mean', 'features.4.block.1.1.running_var', 'features.4.block.1.1.num_batches_tracked', 'features.4.block.2.fc1.weight', 'features.4.block.2.fc1.bias', 'features.4.block.2.fc2.weight', 'features.4.block.2.fc2.bias', 'features.4.block.3.0.weight', 'features.4.block.3.1.weight', 'features.4.block.3.1.bias', 'features.4.block.3.1.running_mean', 'features.4.block.3.1.running_var', 'features.4.block.3.1.num_batches_tracked', 'features.5.block.0.0.weight', 'features.5.block.0.1.weight', 'features.5.block.0.1.bias', 'features.5.block.0.1.running_mean', 'features.5.block.0.1.running_var', 'features.5.block.0.1.num_batches_tracked', 'features.5.block.1.0.weight', 'features.5.block.1.1.weight', 'features.5.block.1.1.bias', 'features.5.block.1.1.running_mean', 'features.5.block.1.1.running_var', 'features.5.block.1.1.num_batches_tracked', 'features.5.block.2.fc1.weight', 'features.5.block.2.fc1.bias', 'features.5.block.2.fc2.weight', 'features.5.block.2.fc2.bias', 'features.5.block.3.0.weight', 'features.5.block.3.1.weight', 'features.5.block.3.1.bias', 'features.5.block.3.1.running_mean', 'features.5.block.3.1.running_var', 'features.5.block.3.1.num_batches_tracked', 'features.6.block.0.0.weight', 'features.6.block.0.1.weight', 'features.6.block.0.1.bias', 'features.6.block.0.1.running_mean', 'features.6.block.0.1.running_var', 'features.6.block.0.1.num_batches_tracked', 'features.6.block.1.0.weight', 'features.6.block.1.1.weight', 'features.6.block.1.1.bias', 'features.6.block.1.1.running_mean', 'features.6.block.1.1.running_var', 'features.6.block.1.1.num_batches_tracked', 'features.6.block.2.fc1.weight', 'features.6.block.2.fc1.bias', 'features.6.block.2.fc2.weight', 'features.6.block.2.fc2.bias', 'features.6.block.3.0.weight', 'features.6.block.3.1.weight', 'features.6.block.3.1.bias', 'features.6.block.3.1.running_mean', 'features.6.block.3.1.running_var', 'features.6.block.3.1.num_batches_tracked', 'features.7.block.0.0.weight', 'features.7.block.0.1.weight', 'features.7.block.0.1.bias', 'features.7.block.0.1.running_mean', 'features.7.block.0.1.running_var', 'features.7.block.0.1.num_batches_tracked', 'features.7.block.1.0.weight', 'features.7.block.1.1.weight', 'features.7.block.1.1.bias', 'features.7.block.1.1.running_mean', 'features.7.block.1.1.running_var', 'features.7.block.1.1.num_batches_tracked', 'features.7.block.2.0.weight', 'features.7.block.2.1.weight', 'features.7.block.2.1.bias', 'features.7.block.2.1.running_mean', 'features.7.block.2.1.running_var', 'features.7.block.2.1.num_batches_tracked', 'features.8.block.0.0.weight', 'features.8.block.0.1.weight', 'features.8.block.0.1.bias', 'features.8.block.0.1.running_mean', 'features.8.block.0.1.running_var', 'features.8.block.0.1.num_batches_tracked', 'features.8.block.1.0.weight', 'features.8.block.1.1.weight', 'features.8.block.1.1.bias', 'features.8.block.1.1.running_mean', 'features.8.block.1.1.running_var', 'features.8.block.1.1.num_batches_tracked', 'features.8.block.2.0.weight', 'features.8.block.2.1.weight', 'features.8.block.2.1.bias', 'features.8.block.2.1.running_mean', 'features.8.block.2.1.running_var', 'features.8.block.2.1.num_batches_tracked', 'features.9.block.0.0.weight', 'features.9.block.0.1.weight', 'features.9.block.0.1.bias', 'features.9.block.0.1.running_mean', 'features.9.block.0.1.running_var', 'features.9.block.0.1.num_batches_tracked', 'features.9.block.1.0.weight', 'features.9.block.1.1.weight', 'features.9.block.1.1.bias', 'features.9.block.1.1.running_mean', 'features.9.block.1.1.running_var', 'features.9.block.1.1.num_batches_tracked', 'features.9.block.2.0.weight', 'features.9.block.2.1.weight', 'features.9.block.2.1.bias', 'features.9.block.2.1.running_mean', 'features.9.block.2.1.running_var', 'features.9.block.2.1.num_batches_tracked', 'features.10.block.0.0.weight', 'features.10.block.0.1.weight', 'features.10.block.0.1.bias', 'features.10.block.0.1.running_mean', 'features.10.block.0.1.running_var', 'features.10.block.0.1.num_batches_tracked', 'features.10.block.1.0.weight', 'features.10.block.1.1.weight', 'features.10.block.1.1.bias', 'features.10.block.1.1.running_mean', 'features.10.block.1.1.running_var', 'features.10.block.1.1.num_batches_tracked', 'features.10.block.2.0.weight', 'features.10.block.2.1.weight', 'features.10.block.2.1.bias', 'features.10.block.2.1.running_mean', 'features.10.block.2.1.running_var', 'features.10.block.2.1.num_batches_tracked', 'features.11.block.0.0.weight', 'features.11.block.0.1.weight', 'features.11.block.0.1.bias', 'features.11.block.0.1.running_mean', 'features.11.block.0.1.running_var', 'features.11.block.0.1.num_batches_tracked', 'features.11.block.1.0.weight', 'features.11.block.1.1.weight', 'features.11.block.1.1.bias', 'features.11.block.1.1.running_mean', 'features.11.block.1.1.running_var', 'features.11.block.1.1.num_batches_tracked', 'features.11.block.2.fc1.weight', 'features.11.block.2.fc1.bias', 'features.11.block.2.fc2.weight', 'features.11.block.2.fc2.bias', 'features.11.block.3.0.weight', 'features.11.block.3.1.weight', 'features.11.block.3.1.bias', 'features.11.block.3.1.running_mean', 'features.11.block.3.1.running_var', 'features.11.block.3.1.num_batches_tracked', 'features.12.block.0.0.weight', 'features.12.block.0.1.weight', 'features.12.block.0.1.bias', 'features.12.block.0.1.running_mean', 'features.12.block.0.1.running_var', 'features.12.block.0.1.num_batches_tracked', 'features.12.block.1.0.weight', 'features.12.block.1.1.weight', 'features.12.block.1.1.bias', 'features.12.block.1.1.running_mean', 'features.12.block.1.1.running_var', 'features.12.block.1.1.num_batches_tracked', 'features.12.block.2.fc1.weight', 'features.12.block.2.fc1.bias', 'features.12.block.2.fc2.weight', 'features.12.block.2.fc2.bias', 'features.12.block.3.0.weight', 'features.12.block.3.1.weight', 'features.12.block.3.1.bias', 'features.12.block.3.1.running_mean', 'features.12.block.3.1.running_var', 'features.12.block.3.1.num_batches_tracked', 'features.13.block.0.0.weight', 'features.13.block.0.1.weight', 'features.13.block.0.1.bias', 'features.13.block.0.1.running_mean', 'features.13.block.0.1.running_var', 'features.13.block.0.1.num_batches_tracked', 'features.13.block.1.0.weight', 'features.13.block.1.1.weight', 'features.13.block.1.1.bias', 'features.13.block.1.1.running_mean', 'features.13.block.1.1.running_var', 'features.13.block.1.1.num_batches_tracked', 'features.13.block.2.fc1.weight', 'features.13.block.2.fc1.bias', 'features.13.block.2.fc2.weight', 'features.13.block.2.fc2.bias', 'features.13.block.3.0.weight', 'features.13.block.3.1.weight', 'features.13.block.3.1.bias', 'features.13.block.3.1.running_mean', 'features.13.block.3.1.running_var', 'features.13.block.3.1.num_batches_tracked', 'features.14.block.0.0.weight', 'features.14.block.0.1.weight', 'features.14.block.0.1.bias', 'features.14.block.0.1.running_mean', 'features.14.block.0.1.running_var', 'features.14.block.0.1.num_batches_tracked', 'features.14.block.1.0.weight', 'features.14.block.1.1.weight', 'features.14.block.1.1.bias', 'features.14.block.1.1.running_mean', 'features.14.block.1.1.running_var', 'features.14.block.1.1.num_batches_tracked', 'features.14.block.2.fc1.weight', 'features.14.block.2.fc1.bias', 'features.14.block.2.fc2.weight', 'features.14.block.2.fc2.bias', 'features.14.block.3.0.weight', 'features.14.block.3.1.weight', 'features.14.block.3.1.bias', 'features.14.block.3.1.running_mean', 'features.14.block.3.1.running_var', 'features.14.block.3.1.num_batches_tracked', 'features.15.block.0.0.weight', 'features.15.block.0.1.weight', 'features.15.block.0.1.bias', 'features.15.block.0.1.running_mean', 'features.15.block.0.1.running_var', 'features.15.block.0.1.num_batches_tracked', 'features.15.block.1.0.weight', 'features.15.block.1.1.weight', 'features.15.block.1.1.bias', 'features.15.block.1.1.running_mean', 'features.15.block.1.1.running_var', 'features.15.block.1.1.num_batches_tracked', 'features.15.block.2.fc1.weight', 'features.15.block.2.fc1.bias', 'features.15.block.2.fc2.weight', 'features.15.block.2.fc2.bias', 'features.15.block.3.0.weight', 'features.15.block.3.1.weight', 'features.15.block.3.1.bias', 'features.15.block.3.1.running_mean', 'features.15.block.3.1.running_var', 'features.15.block.3.1.num_batches_tracked', 'features.16.0.weight', 'features.16.1.weight', 'features.16.1.bias', 'features.16.1.running_mean', 'features.16.1.running_var', 'features.16.1.num_batches_tracked', 'classifier.0.weight', 'classifier.0.bias', 'classifier.3.weight', 'classifier.3.bias']\n",
      "\n",
      "=== Model: ResNet50\\best_glaucoma_model.pth ===\n",
      "Checkpoint keys: ['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias']\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect the actual model files to see if they contain any metadata\n",
    "def inspect_model_checkpoint(model_path):\n",
    "    \"\"\"Inspect a PyTorch model checkpoint for any metadata\"\"\"\n",
    "    try:\n",
    "        checkpoint = torch.load(model_path, map_location='cpu')\n",
    "        print(f\"\\n=== Model: {model_path} ===\")\n",
    "        \n",
    "        if isinstance(checkpoint, dict):\n",
    "            print(\"Checkpoint keys:\", list(checkpoint.keys()))\n",
    "            \n",
    "            # Look for common metadata keys\n",
    "            metadata_keys = ['class_to_idx', 'idx_to_class', 'classes', 'labels']\n",
    "            \n",
    "            for key in metadata_keys:\n",
    "                if key in checkpoint:\n",
    "                    print(f\"{key}: {checkpoint[key]}\")\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {model_path}: {e}\")\n",
    "\n",
    "# Check each model\n",
    "for model_dir in model_dirs:\n",
    "    model_path = os.path.join(model_dir, 'best_glaucoma_model.pth')\n",
    "    if os.path.exists(model_path):\n",
    "        inspect_model_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf133a7",
   "metadata": {},
   "source": [
    "## How to Run This Investigation\n",
    "\n",
    "### Step 1: Open Terminal/Command Prompt\n",
    "1. Press `Windows + R`, type `cmd`, press Enter\n",
    "2. Navigate to your project folder:\n",
    "   ```\n",
    "   cd \"C:\\Users\\bhara\\OneDrive\\Desktop\\GlaucoAI\\Notebooks\"\n",
    "   ```\n",
    "\n",
    "### Step 2: Install Jupyter Notebook (if not installed)\n",
    "```\n",
    "pip install jupyter notebook\n",
    "```\n",
    "\n",
    "### Step 3: Start Jupyter Notebook\n",
    "```\n",
    "jupyter notebook\n",
    "```\n",
    "This will open your web browser with Jupyter interface.\n",
    "\n",
    "### Step 4: Open This Notebook\n",
    "- Click on `model_label_investigation.ipynb` in the Jupyter file browser\n",
    "- Run each cell by clicking the cell and pressing `Shift + Enter`\n",
    "\n",
    "### Alternative: Use VS Code\n",
    "1. Open VS Code\n",
    "2. Install Python extension if not installed\n",
    "3. Open this `.ipynb` file in VS Code\n",
    "4. Click \"Run Cell\" button on each cell\n",
    "\n",
    "### What You'll See\n",
    "- Cell 2: Lists files in each model directory\n",
    "- Cell 3: Checks if model files contain label information\n",
    "- Cell 5: Shows the model architecture\n",
    "\n",
    "**Goal:** Find out if Class 0 = Glaucoma or Class 0 = Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788446c9",
   "metadata": {},
   "source": [
    "## The Solution\n",
    "\n",
    "**Step 1:** Run the cells above to see if the model files contain any metadata about class labels.\n",
    "\n",
    "**Step 2:** If no metadata is found, we need to test with known images:\n",
    "- Take a confirmed glaucoma image â†’ see if model predicts class 0 or class 1\n",
    "- Take a confirmed normal image â†’ see if model predicts class 0 or class 1\n",
    "\n",
    "**Step 3:** Based on the results, we'll know:\n",
    "- If glaucoma images get class 0 â†’ Class 0 = Glaucoma, Class 1 = Normal\n",
    "- If glaucoma images get class 1 â†’ Class 0 = Normal, Class 1 = Glaucoma\n",
    "\n",
    "**Step 4:** Fix the backend API to interpret the classes correctly.\n",
    "\n",
    "This is a common issue in machine learning - the models work correctly, but we're misinterpreting what their outputs mean!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0cf5f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Quick Model Test ===\n",
      "Raw model output: [[ 0.04035787 -0.40559298]]\n",
      "After softmax: [[0.6096761  0.39032394]]\n",
      "Predicted class: 0\n",
      "Class 0 probability: 0.6097\n",
      "Class 1 probability: 0.3903\n",
      "Raw model output: [[ 0.04035787 -0.40559298]]\n",
      "After softmax: [[0.6096761  0.39032394]]\n",
      "Predicted class: 0\n",
      "Class 0 probability: 0.6097\n",
      "Class 1 probability: 0.3903\n"
     ]
    }
   ],
   "source": [
    "# Quick test: Load one model and test with dummy data to see output format\n",
    "def quick_model_test():\n",
    "    \"\"\"Test one model to understand its output structure\"\"\"\n",
    "    print(\"=== Quick Model Test ===\")\n",
    "    \n",
    "    # Try to load ResNet50 model\n",
    "    model_path = \"ResNet50/best_glaucoma_model.pth\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        try:\n",
    "            # Create model\n",
    "            model = models.resnet50(pretrained=True)\n",
    "            model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "            \n",
    "            # Load weights\n",
    "            checkpoint = torch.load(model_path, map_location='cpu')\n",
    "            model.load_state_dict(checkpoint)\n",
    "            model.eval()\n",
    "            \n",
    "            # Test with random input (simulating an image)\n",
    "            dummy_input = torch.randn(1, 3, 224, 224)  # Batch=1, RGB, 224x224\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(dummy_input)\n",
    "                probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                predicted_class = torch.argmax(probabilities, dim=1)\n",
    "                \n",
    "                print(f\"Raw model output: {outputs.numpy()}\")\n",
    "                print(f\"After softmax: {probabilities.numpy()}\")\n",
    "                print(f\"Predicted class: {predicted_class.item()}\")\n",
    "                print(f\"Class 0 probability: {probabilities[0][0].item():.4f}\")\n",
    "                print(f\"Class 1 probability: {probabilities[0][1].item():.4f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error testing model: {e}\")\n",
    "    else:\n",
    "        print(f\"Model file not found: {model_path}\")\n",
    "        print(\"Make sure you're in the Notebooks directory!\")\n",
    "\n",
    "# Run the test\n",
    "quick_model_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a6e8ac",
   "metadata": {},
   "source": [
    "## What This Investigation Means\n",
    "\n",
    "**The Problem:** Your AI model predicted a glaucoma image as \"Normal\" when it should have detected glaucoma.\n",
    "\n",
    "**Why This Happens:** During training, AI models learn to associate:\n",
    "- Class 0 with one condition (e.g., glaucoma OR normal)\n",
    "- Class 1 with the other condition (e.g., normal OR glaucoma)\n",
    "\n",
    "**The Issue:** We don't know which class number means what! The model might have learned:\n",
    "- Class 0 = Glaucoma, Class 1 = Normal, OR\n",
    "- Class 0 = Normal, Class 1 = Glaucoma\n",
    "\n",
    "**How PyTorch Assigns Classes:**\n",
    "When training with folders of images, PyTorch automatically assigns class numbers **alphabetically**:\n",
    "- If folders were named \"glaucoma\" and \"normal\" â†’ Class 0 = glaucoma, Class 1 = normal\n",
    "- If folders were named \"normal\" and \"glaucoma\" â†’ Class 0 = normal, Class 1 = glaucoma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d96ccc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models are trained to output 2 classes:\n",
      "- Class 0: Could be Normal OR Glaucoma\n",
      "- Class 1: Could be Glaucoma OR Normal\n",
      "\n",
      "We need to figure out which is which!\n"
     ]
    }
   ],
   "source": [
    "# Let's create a simple test to understand what our models actually learned\n",
    "def create_test_model(model_type):\n",
    "    \"\"\"Create the same model architecture used in training\"\"\"\n",
    "    if model_type == 'resnet50':\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 2)  # 2 classes: 0 and 1\n",
    "    elif model_type == 'mobilenet_v3_large':\n",
    "        model = models.mobilenet_v3_large(pretrained=True) \n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Linear(model.classifier[0].in_features, 1280),\n",
    "            nn.Hardswish(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(1280, 2)  # 2 classes: 0 and 1\n",
    "        )\n",
    "    elif model_type == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(model.classifier[1].in_features, 2)  # 2 classes: 0 and 1\n",
    "        )\n",
    "    return model\n",
    "\n",
    "print(\"Models are trained to output 2 classes:\")\n",
    "print(\"- Class 0: Could be Normal OR Glaucoma\")\n",
    "print(\"- Class 1: Could be Glaucoma OR Normal\") \n",
    "print(\"\\nWe need to figure out which is which!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4ea67",
   "metadata": {},
   "source": [
    "## After Running This Notebook\n",
    "\n",
    "### If You Find Label Information:\n",
    "- Look for output like `class_to_idx: {'glaucoma': 0, 'normal': 1}`\n",
    "- This tells us exactly which class means what\n",
    "\n",
    "### If No Label Information Found:\n",
    "1. **Test with your glaucoma image:**\n",
    "   - Start your backend server: `cd ..\\backend` then `python app.py`\n",
    "   - Upload the same glaucoma image that was misclassified\n",
    "   - Check the backend terminal logs for \"Raw model outputs\"\n",
    "   - If it shows `predicted_class=1` for glaucoma â†’ Class 0 = Normal, Class 1 = Glaucoma\n",
    "   - If it shows `predicted_class=0` for glaucoma â†’ Class 0 = Glaucoma, Class 1 = Normal\n",
    "\n",
    "2. **Fix the backend:**\n",
    "   - Update `labels_swapped` in `MODEL_CONFIGS` based on findings\n",
    "   - Restart backend server\n",
    "   - Test again\n",
    "\n",
    "### Terminal Commands Summary:\n",
    "```bash\n",
    "# Navigate to project\n",
    "cd \"C:\\Users\\bhara\\OneDrive\\Desktop\\GlaucoAI\"\n",
    "\n",
    "# Start backend (in one terminal)\n",
    "cd backend\n",
    "python app.py\n",
    "\n",
    "# Start frontend (in another terminal) \n",
    "cd glaucoma-frontend\n",
    "npm run dev\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b402e5cc",
   "metadata": {},
   "source": [
    "## Quick Fix Test\n",
    "\n",
    "To determine correct labels, test with known images and see which class indices they get predicted as.\n",
    "\n",
    "**Common PyTorch ImageFolder Behavior:**\n",
    "- Folders named alphabetically: \"glaucoma\" then \"normal\" â†’ class 0 = glaucoma, class 1 = normal\n",
    "- This is likely why your glaucoma image was misclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6af3ec",
   "metadata": {},
   "source": [
    "## ğŸš¨ CRITICAL ISSUE DISCOVERED\n",
    "\n",
    "**Problem:** The models appear to be biased - they predict one class too frequently!\n",
    "\n",
    "**What's happening:**\n",
    "- Original: Glaucoma images â†’ \"Normal\" (wrong)\n",
    "- After \"fix\": Normal images â†’ \"Glaucoma\" (wrong again!)\n",
    "\n",
    "This suggests the models themselves have issues, not just label confusion.\n",
    "\n",
    "**Possible causes:**\n",
    "1. **Model bias:** Trained on imbalanced dataset\n",
    "2. **Poor training:** Models didn't learn proper features\n",
    "3. **Threshold issues:** Decision boundary is wrong\n",
    "4. **Data leakage:** Training data contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68fdda44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ANALYZING EfficientNet\n",
      "==================================================\n",
      "Testing with 10 random inputs...\n",
      "Prediction distribution:\n",
      "  Class 0 predictions: 9/10\n",
      "  Class 1 predictions: 1/10\n",
      "  Average Class 0 probability: 0.650\n",
      "  Average Class 1 probability: 0.350\n",
      "âš ï¸  STRONG BIAS toward Class 0\n",
      "\n",
      "==================================================\n",
      "ANALYZING MobileNetV3\n",
      "==================================================\n",
      "Testing with 10 random inputs...\n",
      "Prediction distribution:\n",
      "  Class 0 predictions: 9/10\n",
      "  Class 1 predictions: 1/10\n",
      "  Average Class 0 probability: 0.650\n",
      "  Average Class 1 probability: 0.350\n",
      "âš ï¸  STRONG BIAS toward Class 0\n",
      "\n",
      "==================================================\n",
      "ANALYZING MobileNetV3\n",
      "==================================================\n",
      "Testing with 10 random inputs...\n",
      "Prediction distribution:\n",
      "  Class 0 predictions: 10/10\n",
      "  Class 1 predictions: 0/10\n",
      "  Average Class 0 probability: 0.837\n",
      "  Average Class 1 probability: 0.163\n",
      "âš ï¸  STRONG BIAS toward Class 0\n",
      "âš ï¸  Model heavily favors Class 0\n",
      "\n",
      "==================================================\n",
      "ANALYZING ResNet50\n",
      "==================================================\n",
      "Testing with 10 random inputs...\n",
      "Prediction distribution:\n",
      "  Class 0 predictions: 10/10\n",
      "  Class 1 predictions: 0/10\n",
      "  Average Class 0 probability: 0.837\n",
      "  Average Class 1 probability: 0.163\n",
      "âš ï¸  STRONG BIAS toward Class 0\n",
      "âš ï¸  Model heavily favors Class 0\n",
      "\n",
      "==================================================\n",
      "ANALYZING ResNet50\n",
      "==================================================\n",
      "Testing with 10 random inputs...\n",
      "Prediction distribution:\n",
      "  Class 0 predictions: 10/10\n",
      "  Class 1 predictions: 0/10\n",
      "  Average Class 0 probability: 0.604\n",
      "  Average Class 1 probability: 0.396\n",
      "âš ï¸  STRONG BIAS toward Class 0\n",
      "Prediction distribution:\n",
      "  Class 0 predictions: 10/10\n",
      "  Class 1 predictions: 0/10\n",
      "  Average Class 0 probability: 0.604\n",
      "  Average Class 1 probability: 0.396\n",
      "âš ï¸  STRONG BIAS toward Class 0\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive model analysis - let's test ALL models with various inputs\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_model_behavior(model_name, model_type, model_path):\n",
    "    \"\"\"Comprehensive analysis of model behavior\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ANALYZING {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"âŒ Model not found: {model_path}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Load model\n",
    "        if model_type == 'resnet50':\n",
    "            model = models.resnet50(pretrained=True)\n",
    "            model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "        elif model_type == 'mobilenet_v3_large':\n",
    "            model = models.mobilenet_v3_large(pretrained=True)\n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.Linear(model.classifier[0].in_features, 1280),\n",
    "                nn.Hardswish(),\n",
    "                nn.Dropout(p=0.2),\n",
    "                nn.Linear(1280, 2)\n",
    "            )\n",
    "        elif model_type == 'efficientnet_b0':\n",
    "            model = models.efficientnet_b0(pretrained=True)\n",
    "            model.classifier = nn.Sequential(\n",
    "                nn.Dropout(p=0.2),\n",
    "                nn.Linear(model.classifier[1].in_features, 2)\n",
    "            )\n",
    "        \n",
    "        checkpoint = torch.load(model_path, map_location='cpu')\n",
    "        model.load_state_dict(checkpoint)\n",
    "        model.eval()\n",
    "        \n",
    "        # Test with multiple random inputs to see prediction patterns\n",
    "        predictions = []\n",
    "        class_0_probs = []\n",
    "        class_1_probs = []\n",
    "        \n",
    "        print(\"Testing with 10 random inputs...\")\n",
    "        for i in range(10):\n",
    "            dummy_input = torch.randn(1, 3, 224, 224)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(dummy_input)\n",
    "                probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "                \n",
    "                predictions.append(predicted_class)\n",
    "                class_0_probs.append(probabilities[0][0].item())\n",
    "                class_1_probs.append(probabilities[0][1].item())\n",
    "        \n",
    "        # Analyze patterns\n",
    "        class_0_count = predictions.count(0)\n",
    "        class_1_count = predictions.count(1)\n",
    "        \n",
    "        print(f\"Prediction distribution:\")\n",
    "        print(f\"  Class 0 predictions: {class_0_count}/10\")\n",
    "        print(f\"  Class 1 predictions: {class_1_count}/10\")\n",
    "        print(f\"  Average Class 0 probability: {np.mean(class_0_probs):.3f}\")\n",
    "        print(f\"  Average Class 1 probability: {np.mean(class_1_probs):.3f}\")\n",
    "        \n",
    "        # Check for bias\n",
    "        if class_0_count >= 8:\n",
    "            print(\"âš ï¸  STRONG BIAS toward Class 0\")\n",
    "        elif class_1_count >= 8:\n",
    "            print(\"âš ï¸  STRONG BIAS toward Class 1\")\n",
    "        elif abs(class_0_count - class_1_count) <= 2:\n",
    "            print(\"âœ… Balanced predictions\")\n",
    "        else:\n",
    "            print(\"ğŸ”¸ Slight bias detected\")\n",
    "            \n",
    "        # Check probability distributions\n",
    "        avg_class_0 = np.mean(class_0_probs)\n",
    "        avg_class_1 = np.mean(class_1_probs)\n",
    "        \n",
    "        if avg_class_0 > 0.8:\n",
    "            print(\"âš ï¸  Model heavily favors Class 0\")\n",
    "        elif avg_class_1 > 0.8:\n",
    "            print(\"âš ï¸  Model heavily favors Class 1\")\n",
    "            \n",
    "        return {\n",
    "            'model_name': model_name,\n",
    "            'class_0_count': class_0_count,\n",
    "            'class_1_count': class_1_count,\n",
    "            'avg_class_0_prob': avg_class_0,\n",
    "            'avg_class_1_prob': avg_class_1\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error analyzing {model_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test all models\n",
    "model_configs = {\n",
    "    'EfficientNet': ('efficientnet_b0', 'EfficientNet/best_glaucoma_model.pth'),\n",
    "    'MobileNetV3': ('mobilenet_v3_large', 'MobileNetV3-Large/best_glaucoma_model.pth'),\n",
    "    'ResNet50': ('resnet50', 'ResNet50/best_glaucoma_model.pth')\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model_name, (model_type, model_path) in model_configs.items():\n",
    "    result = analyze_model_behavior(model_name, model_type, model_path)\n",
    "    if result:\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b37ba9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY OF ALL MODELS\n",
      "============================================================\n",
      "\n",
      "EfficientNet:\n",
      "  Class 0: 9/10 predictions\n",
      "  Class 1: 1/10 predictions\n",
      "  Avg probabilities: Class 0=0.650, Class 1=0.350\n",
      "  ğŸ”´ PROBLEM: EfficientNet is biased toward Class 0\n",
      "\n",
      "MobileNetV3:\n",
      "  Class 0: 10/10 predictions\n",
      "  Class 1: 0/10 predictions\n",
      "  Avg probabilities: Class 0=0.837, Class 1=0.163\n",
      "  ğŸ”´ PROBLEM: MobileNetV3 is biased toward Class 0\n",
      "\n",
      "ResNet50:\n",
      "  Class 0: 10/10 predictions\n",
      "  Class 1: 0/10 predictions\n",
      "  Avg probabilities: Class 0=0.604, Class 1=0.396\n",
      "  ğŸ”´ PROBLEM: ResNet50 is biased toward Class 0\n",
      "\n",
      "============================================================\n",
      "RECOMMENDATIONS\n",
      "============================================================\n",
      "1. If models show strong bias, they need retraining\n",
      "2. Check training data for class imbalance\n",
      "3. Consider using different trained models\n",
      "4. May need to adjust decision thresholds\n"
     ]
    }
   ],
   "source": [
    "# Summary analysis\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUMMARY OF ALL MODELS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if results:\n",
    "    for result in results:\n",
    "        print(f\"\\n{result['model_name']}:\")\n",
    "        print(f\"  Class 0: {result['class_0_count']}/10 predictions\")\n",
    "        print(f\"  Class 1: {result['class_1_count']}/10 predictions\")\n",
    "        print(f\"  Avg probabilities: Class 0={result['avg_class_0_prob']:.3f}, Class 1={result['avg_class_1_prob']:.3f}\")\n",
    "        \n",
    "        # Diagnosis\n",
    "        if result['class_0_count'] >= 8 or result['avg_class_0_prob'] > 0.8:\n",
    "            print(f\"  ğŸ”´ PROBLEM: {result['model_name']} is biased toward Class 0\")\n",
    "        elif result['class_1_count'] >= 8 or result['avg_class_1_prob'] > 0.8:\n",
    "            print(f\"  ğŸ”´ PROBLEM: {result['model_name']} is biased toward Class 1\")\n",
    "        else:\n",
    "            print(f\"  âœ… {result['model_name']} appears balanced\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"1. If models show strong bias, they need retraining\")\n",
    "print(\"2. Check training data for class imbalance\")\n",
    "print(\"3. Consider using different trained models\")\n",
    "print(\"4. May need to adjust decision thresholds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d3eddde",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (875642759.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    // ...existing code...\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7e9b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea620379",
   "metadata": {},
   "source": [
    "## ğŸ”§ Potential Solutions\n",
    "\n",
    "### If Models Are Biased (Predict Same Class Too Often):\n",
    "\n",
    "**Option 1: Adjust Decision Threshold**\n",
    "- Instead of using 0.5 as cutoff, find optimal threshold\n",
    "- Test with: if prob_glaucoma > 0.3 then \"Glaucoma\"\n",
    "\n",
    "**Option 2: Ensemble Approach**\n",
    "- Use all 3 models and average their predictions\n",
    "- More robust than single model\n",
    "\n",
    "**Option 3: Model Retraining**\n",
    "- Retrain with balanced dataset\n",
    "- Use proper data augmentation\n",
    "- Implement class weighting\n",
    "\n",
    "**Option 4: Use Pre-trained Medical Models**\n",
    "- Look for publicly available glaucoma models\n",
    "- Use models trained on larger, balanced datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116630dd",
   "metadata": {},
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda96c5c",
   "metadata": {},
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf8cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af3e0f3",
   "metadata": {},
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a61bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2febd1",
   "metadata": {},
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aacbba3",
   "metadata": {},
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30242866",
   "metadata": {},
   "source": [
    "# Model Label Investigation\n",
    "\n",
    "This notebook investigates the label mapping used during training to understand why predictions might be incorrect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f98f29a",
   "metadata": {},
   "source": [
    "## ğŸ“Š How to Interpret Your Results\n",
    "\n",
    "**Tell me what you saw in the outputs above, and I'll help you understand what it means!**\n",
    "\n",
    "### What to Look For:\n",
    "\n",
    "**1. From Cell 2 (Directory Listing):**\n",
    "- Did you see `.pth` files in each model folder?\n",
    "- Any other files like `.json`, `.txt`, or `.log`?\n",
    "\n",
    "**2. From Cell 3 (Model Metadata):**\n",
    "- Did it show \"Checkpoint keys: [...]\"?\n",
    "- Any mention of `class_to_idx` or `classes`?\n",
    "- Or just \"Direct state_dict (no metadata)\"?\n",
    "\n",
    "**3. From Cell 6 (Quick Model Test):**\n",
    "- What were the \"Class 0 probability\" and \"Class 1 probability\" values?\n",
    "- Which class did it predict (0 or 1)?\n",
    "\n",
    "**4. From Cell 10-11 (Comprehensive Analysis):**\n",
    "- How many times did each model predict Class 0 vs Class 1?\n",
    "- What were the average probabilities?\n",
    "- Did you see any \"ğŸ”´ PROBLEM\" or \"âš ï¸ BIAS\" warnings?\n",
    "\n",
    "### Common Result Patterns:\n",
    "\n",
    "**Pattern A: Strong Bias (BAD)**\n",
    "```\n",
    "Class 0 predictions: 9/10\n",
    "Class 1 predictions: 1/10\n",
    "ğŸ”´ PROBLEM: Model is biased toward Class 0\n",
    "```\n",
    "*This means the model almost always predicts the same class - it's broken!*\n",
    "\n",
    "**Pattern B: Balanced (GOOD)**\n",
    "```\n",
    "Class 0 predictions: 4/10\n",
    "Class 1 predictions: 6/10\n",
    "âœ… Model appears balanced\n",
    "```\n",
    "*This means the model can distinguish between classes properly.*\n",
    "\n",
    "**Pattern C: Moderate Bias (FIXABLE)**\n",
    "```\n",
    "Class 0 predictions: 7/10\n",
    "Class 1 predictions: 3/10\n",
    "ğŸ”¸ Slight bias detected\n",
    "```\n",
    "*This can be fixed with threshold adjustment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031f7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e563675",
   "metadata": {},
   "outputs": [],
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae09c1e",
   "metadata": {},
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d952ee",
   "metadata": {},
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f970787",
   "metadata": {},
   "outputs": [],
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a87c97",
   "metadata": {},
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9077aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6c92eb",
   "metadata": {},
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6695e62",
   "metadata": {},
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f47fc8",
   "metadata": {},
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782356d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d717526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a8d9f",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c974652",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737c2407",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdd7075",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7075a1d",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93ae5ca",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e746fe",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a41cf2",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cdf1d9",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f9ec49",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369da000",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaf54e6",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5504a",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47d7844",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445883ec",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3c3d8d",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69138c83",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091cdb4f",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c467f",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982620f3",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80131b",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5236c96a",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d40d13",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd79077",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5e3f6a",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420a2ac",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fffe15",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33edd45",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67883e3",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6a5458",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c36e81c",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbd47e1",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0651e86",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e44113b",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de179353",
   "metadata": {},
   "source": [
    "## ğŸ¯ What Your Results Mean\n",
    "\n",
    "**Your results show a MAJOR PROBLEM:**\n",
    "\n",
    "```\n",
    "EfficientNet: 9/10 predictions â†’ Class 0 (STRONG BIAS)\n",
    "MobileNetV3: 10/10 predictions â†’ Class 0 (EXTREME BIAS) \n",
    "ResNet50: 10/10 predictions â†’ Class 0 (EXTREME BIAS)\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- âŒ All models are broken - they almost always predict Class 0\n",
    "- ğŸ” This explains why both glaucoma AND normal images get the same prediction\n",
    "- ğŸ’¡ The models didn't learn to distinguish between classes properly\n",
    "\n",
    "**Root Cause Analysis:**\n",
    "1. **Training Data Imbalance**: Likely had way more Class 0 images than Class 1\n",
    "2. **Poor Training**: Models learned to just guess the majority class\n",
    "3. **Label Issue**: We still don't know if Class 0 = Normal or Class 0 = Glaucoma\n",
    "\n",
    "**Evidence from your tests:**\n",
    "- Original: Glaucoma â†’ \"Normal\" \n",
    "- After label swap: Normal â†’ \"Glaucoma\"\n",
    "- Both scenarios = wrong because models always pick same class!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
